{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "All rights reserved.\n",
    "\n",
    "This source code is licensed under the license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALSA Attack Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "paths = [\"/path/to/logs/he_29/*/\", \"/path/to/logs/he_50_ternary/*/\"]\n",
    "file_paths = [x for path in paths for x in glob.glob(path)]\n",
    "print(len(file_paths))\n",
    "information = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in file_paths:\n",
    "  exp_id = os.path.basename(file_path)\n",
    "  log_file_path = os.path.join(file_path, \"train.log\")\n",
    "  ckpt_file_path = os.path.join(file_path, \"checkpoint.pth\")\n",
    "  information[file_path] = {}\n",
    "  with open(log_file_path, 'r') as file1:\n",
    "    lines = file1.readlines()\n",
    "    for line in lines:\n",
    "      if not line:\n",
    "          break\n",
    "      if \"Predicted\" in line:\n",
    "        information[file_path][\"success\"] = True\n",
    "        for key, val in torch.load(ckpt_file_path,map_location=torch.device('cpu'))[\"params\"].items():\n",
    "          information[file_path][key] = val\n",
    "      if \"[hours:\" in line:\n",
    "        information[file_path][\"time\"] = float(line.split(\" \")[-3].strip(\",\"))\n",
    "        information[file_path][\"epoch\"] = int(line.split(\" \")[-1].strip(\"]\\n\"))\n",
    "      if \"Error\" in line:\n",
    "        information[file_path][\"error\"] = line\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total n successful: 21\n",
      "hamming weights recovered: [7, 8, 9, 10, 11, 12, 13, 14, 16, 17]\n",
      "\n",
      "he_29 h:  7 recoveries:  3\n",
      "min recovery time:  2.8\n",
      "min num epochs:  2\n",
      "\n",
      "he_29 h:  8 recoveries:  1\n",
      "min recovery time:  15.9\n",
      "min num epochs:  12\n",
      "\n",
      "he_29 h:  9 recoveries:  2\n",
      "min recovery time:  3.1\n",
      "min num epochs:  3\n",
      "\n",
      "he_29 h:  10 recoveries:  1\n",
      "min recovery time:  17.8\n",
      "min num epochs:  11\n",
      "\n",
      "he_50_ternary h:  11 recoveries:  3\n",
      "min recovery time:  4.7\n",
      "min num epochs:  3\n",
      "\n",
      "he_50_ternary h:  12 recoveries:  3\n",
      "min recovery time:  1.1\n",
      "min num epochs:  1\n",
      "\n",
      "he_50_ternary h:  13 recoveries:  4\n",
      "min recovery time:  6.3\n",
      "min num epochs:  3\n",
      "\n",
      "he_50_ternary h:  14 recoveries:  1\n",
      "min recovery time:  3.9\n",
      "min num epochs:  2\n",
      "\n",
      "he_50_ternary h:  16 recoveries:  2\n",
      "min recovery time:  20.4\n",
      "min num epochs:  9\n",
      "\n",
      "he_50_ternary h:  17 recoveries:  1\n",
      "min recovery time:  5.3\n",
      "min num epochs:  4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(information).T\n",
    "try:\n",
    "  df.success.fillna(False, inplace=True)\n",
    "except AttributeError:\n",
    "  print(\"no successes for following experiments: \", paths)\n",
    "\n",
    "# remove the ones that don't have \"Attack took\", they failed because of something else\n",
    "df = df[df.time.notna()]\n",
    "print(f\"total n successful: {len(df[df.success])}\")\n",
    "print(f\"hamming weights recovered: {sorted(df[df.success].hamming.unique())}\")\n",
    "print()\n",
    "\n",
    "\n",
    "for exp in df.exp_name.unique():\n",
    "    success_df = df[(df.success) & (df.exp_name == exp)]\n",
    "    for h in sorted(success_df.hamming.unique()):\n",
    "        new_df = success_df[success_df.hamming == h]\n",
    "        print(exp, \"h: \", h, \"recoveries: \", len(new_df))\n",
    "        print(\"min recovery time: \", new_df[\"time\"].min())\n",
    "        print(\"min num epochs: \", new_df[\"epoch\"].min())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC Attack Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    }
   ],
   "source": [
    "expnames = [\"cc_26_ternary_he_final\", \"cc_29_ternary_he_final\", \"cc_50_ternary_he_final\"]\n",
    "paths = [f\"/path/to/logs/{expname}/**/*.stdout\" for expname in expnames]\n",
    "file_paths = [x for path in paths for x in glob.glob(path)]\n",
    "print(len(file_paths))\n",
    "information = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in file_paths:\n",
    "  information[file_path] = {}\n",
    "\n",
    "  with open(file_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "      if \"SUCCESS\" in line:\n",
    "        information[file_path][\"success\"] = True\n",
    "      if \"grid_params\" in line:\n",
    "        for key, val in json.loads(line[line.index(\"{\"):]).items():\n",
    "          information[file_path][key] = val\n",
    "      if \"swept_params\" in line:\n",
    "        for key, val in json.loads(line[line.index(\"{\"):]).items():\n",
    "          information[file_path][key] = val\n",
    "      if \"Attack took\" in line:\n",
    "        information[file_path][\"time\"] = float(line.split(\" \")[-2]) / 3600.0\n",
    "      match = re.search(r'\"full_hw\": (\\d+)', line)\n",
    " \n",
    "      if match:\n",
    "        full_hw = int(match.group(1)) \n",
    "        information[file_path][\"bf_hw\"] = full_hw\n",
    "      if \"minhi = \" in line:\n",
    "        _, minhi = line.split(\"=\")\n",
    "        minhi = int(minhi.split(\",\")[0].strip())\n",
    "        information[file_path][\"minhi\"] = minhi\n",
    "\n",
    "df = pd.DataFrame(information).T\n",
    "try:\n",
    "  df.success.fillna(False, inplace=True)\n",
    "except AttributeError:\n",
    "  print(\"no successes for following experiments: \", expnames, len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_26_ternary_he_final\n",
      "n successful: 24\n",
      "hamming weight [4, 5, 6, 7]\n",
      "       success\n",
      "bf_hw         \n",
      "4           10\n",
      "5            7\n",
      "6            5\n",
      "7            2\n",
      "8            0\n",
      "9            0\n",
      "hamming weight:  4\n",
      "min recovery time:  0.028533690306875442\n",
      "hamming weight:  5\n",
      "min recovery time:  0.04477666106488969\n",
      "hamming weight:  6\n",
      "min recovery time:  0.39132829633024\n",
      "hamming weight:  7\n",
      "min recovery time:  0.4141557166311476\n",
      "\n",
      "cc_29_ternary_he_final\n",
      "n successful: 32\n",
      "hamming weight [7, 8, 9, 12]\n",
      "       success\n",
      "bf_hw         \n",
      "7           10\n",
      "8           11\n",
      "9           10\n",
      "10           0\n",
      "11           0\n",
      "12           1\n",
      "13           0\n",
      "hamming weight:  7\n",
      "min recovery time:  0.03257233096493615\n",
      "hamming weight:  8\n",
      "min recovery time:  0.07510364804002974\n",
      "hamming weight:  9\n",
      "min recovery time:  0.03067563282118903\n",
      "hamming weight:  12\n",
      "min recovery time:  0.13082878172397613\n",
      "\n",
      "cc_50_ternary_he_final\n",
      "n successful: 70\n",
      "hamming weight [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "       success\n",
      "bf_hw         \n",
      "11          10\n",
      "12          10\n",
      "13          10\n",
      "14           9\n",
      "15           7\n",
      "16           6\n",
      "17           6\n",
      "18           4\n",
      "19           6\n",
      "20           2\n",
      "hamming weight:  11\n",
      "min recovery time:  0.058706015083524916\n",
      "hamming weight:  12\n",
      "min recovery time:  0.05757582836680942\n",
      "hamming weight:  13\n",
      "min recovery time:  0.043641759289635554\n",
      "hamming weight:  14\n",
      "min recovery time:  0.0470423776573605\n",
      "hamming weight:  15\n",
      "min recovery time:  0.059975393149587844\n",
      "hamming weight:  16\n",
      "min recovery time:  0.04619442886776394\n",
      "hamming weight:  17\n",
      "min recovery time:  0.054852531022495696\n",
      "hamming weight:  18\n",
      "min recovery time:  1.9405505117442874\n",
      "hamming weight:  19\n",
      "min recovery time:  0.06636764844258626\n",
      "hamming weight:  20\n",
      "min recovery time:  4.157956307993995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for exp in df.exp_name.unique():\n",
    "  mini_df = df[df.exp_name == exp]\n",
    "  success_df = mini_df[mini_df.success]\n",
    "  print(exp)\n",
    "  print(f\"n successful: {len(success_df)}\")\n",
    "  print(f\"hamming weight {sorted(success_df.full_hw.unique())}\")\n",
    "  print(mini_df.groupby(\"bf_hw\").sum(numeric_only=True))\n",
    "  for hw in sorted(success_df.bf_hw.unique()):\n",
    "    mini_success_df = success_df[success_df.bf_hw == hw]\n",
    "    # print(mini_success_df[[\"time\", \"bf_hw\", \"seed\"]].sort_values([\"bf_hw\", \"time\"]))\n",
    "    print(\"hamming weight: \", hw)\n",
    "    print(\"min recovery time: \", mini_success_df.time.min())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
